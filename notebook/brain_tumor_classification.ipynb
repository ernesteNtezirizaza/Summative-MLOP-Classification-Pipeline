{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Tumor MRI Classification - Complete ML Pipeline\n",
    "\n",
    "This notebook demonstrates the complete machine learning pipeline for brain tumor classification from MRI images.\n",
    "\n",
    "## Dataset\n",
    "- **Source**: Kaggle - Brain Tumor MRI Dataset\n",
    "- **Classes**: Glioma, Meningioma, No Tumor, Pituitary\n",
    "- **Structure**: Train/Test split with class subdirectories\n",
    "\n",
    "## Pipeline Steps:\n",
    "1. Data Acquisition and Exploration\n",
    "2. Data Preprocessing and Feature Extraction\n",
    "3. Model Creation (Transfer Learning)\n",
    "4. Model Training with Optimization\n",
    "5. Model Evaluation with Multiple Metrics\n",
    "6. Model Testing and Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Sklearn for evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Import custom modules\n",
    "from preprocessing import extract_features_from_directory, prepare_data_for_training, get_class_names\n",
    "from model import BrainTumorClassifier\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Acquisition and Exploration\n",
    "\n",
    "Let's first explore the dataset structure and understand the data distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore dataset structure\n",
    "data_dir = '../data/train'\n",
    "test_dir = '../data/test'\n",
    "\n",
    "# Get class names\n",
    "class_names = get_class_names(data_dir)\n",
    "print(f\"Classes found: {class_names}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "\n",
    "# Count images per class in training set\n",
    "train_counts = {}\n",
    "for class_name in class_names:\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "    if os.path.exists(class_path):\n",
    "        count = len([f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        train_counts[class_name] = count\n",
    "        print(f\"Training - {class_name}: {count} images\")\n",
    "\n",
    "# Count images per class in test set\n",
    "test_counts = {}\n",
    "for class_name in class_names:\n",
    "    class_path = os.path.join(test_dir, class_name)\n",
    "    if os.path.exists(class_path):\n",
    "        count = len([f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        test_counts[class_name] = count\n",
    "        print(f\"Test - {class_name}: {count} images\")\n",
    "\n",
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Training set distribution\n",
    "axes[0].bar(train_counts.keys(), train_counts.values(), color='skyblue')\n",
    "axes[0].set_title('Training Set - Class Distribution')\n",
    "axes[0].set_xlabel('Class')\n",
    "axes[0].set_ylabel('Number of Images')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Test set distribution\n",
    "axes[1].bar(test_counts.keys(), test_counts.values(), color='lightcoral')\n",
    "axes[1].set_title('Test Set - Class Distribution')\n",
    "axes[1].set_xlabel('Class')\n",
    "axes[1].set_ylabel('Number of Images')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTotal training images: {sum(train_counts.values())}\")\n",
    "print(f\"Total test images: {sum(test_counts.values())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images from each class\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, class_name in enumerate(class_names):\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "    if os.path.exists(class_path):\n",
    "        images = [f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        if images:\n",
    "            img_path = os.path.join(class_path, images[0])\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            axes[idx].imshow(img)\n",
    "            axes[idx].set_title(f'{class_name}\\nSample Image')\n",
    "            axes[idx].axis('off')\n",
    "            axes[idx+4].imshow(cv2.cvtColor(cv2.imread(os.path.join(class_path, images[1] if len(images) > 1 else images[0])), cv2.COLOR_BGR2RGB))\n",
    "            axes[idx+4].set_title(f'{class_name}\\nSample Image 2')\n",
    "            axes[idx+4].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Feature Extraction\n",
    "\n",
    "Extract features from images and save to CSV for analysis and visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from training data\n",
    "print(\"Extracting features from training data...\")\n",
    "train_features_df = extract_features_from_directory(data_dir, '../image_features_train.csv')\n",
    "\n",
    "print(f\"\\nTraining features shape: {train_features_df.shape}\")\n",
    "print(f\"Feature columns: {train_features_df.columns.tolist()}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "train_features_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from test data\n",
    "print(\"Extracting features from test data...\")\n",
    "test_features_df = extract_features_from_directory(test_dir, '../image_features_test.csv')\n",
    "\n",
    "print(f\"\\nTest features shape: {test_features_df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "test_features_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze extracted features\n",
    "if 'class' in train_features_df.columns:\n",
    "    print(\"Feature Statistics by Class:\")\n",
    "    print(train_features_df.groupby('class').describe())\n",
    "    \n",
    "    # Visualize feature distributions\n",
    "    numeric_cols = train_features_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if 'class' in numeric_cols:\n",
    "        numeric_cols.remove('class')\n",
    "    \n",
    "    # Plot distributions for key features\n",
    "    key_features = ['mean_intensity', 'std_intensity', 'gradient_mean', 'hist_mean']\n",
    "    available_features = [f for f in key_features if f in numeric_cols]\n",
    "    \n",
    "    if available_features:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for idx, feature in enumerate(available_features[:4]):\n",
    "            for class_name in class_names:\n",
    "                class_data = train_features_df[train_features_df['class'] == class_name][feature]\n",
    "                axes[idx].hist(class_data, alpha=0.5, label=class_name, bins=30)\n",
    "            axes[idx].set_title(f'Distribution of {feature}')\n",
    "            axes[idx].set_xlabel(feature)\n",
    "            axes[idx].set_ylabel('Frequency')\n",
    "            axes[idx].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Creation - Transfer Learning with VGG16\n",
    "\n",
    "We'll use transfer learning with a pre-trained VGG16 model as the base, then add custom layers for our classification task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data generators with augmentation\n",
    "print(\"Preparing data generators...\")\n",
    "train_gen, val_gen = prepare_data_for_training(\n",
    "    data_dir,\n",
    "    img_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining samples: {train_gen.samples}\")\n",
    "print(f\"Validation samples: {val_gen.samples}\")\n",
    "print(f\"Classes: {list(train_gen.class_indices.keys())}\")\n",
    "print(f\"Number of classes: {len(train_gen.class_indices)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and build the model\n",
    "print(\"Creating model...\")\n",
    "classifier = BrainTumorClassifier(\n",
    "    img_size=(224, 224),\n",
    "    num_classes=len(class_names),\n",
    "    base_model_name='VGG16'\n",
    ")\n",
    "classifier.class_names = class_names\n",
    "classifier.build_model()\n",
    "\n",
    "# Display model architecture\n",
    "classifier.model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training with Optimization Techniques\n",
    "\n",
    "We'll use several optimization techniques:\n",
    "- **Early Stopping**: Prevent overfitting\n",
    "- **Learning Rate Reduction**: Adaptive learning rate\n",
    "- **Data Augmentation**: Increase dataset diversity\n",
    "- **Dropout Regularization**: Prevent overfitting\n",
    "- **Batch Normalization**: Stabilize training\n",
    "- **Fine-tuning**: Unfreeze and retrain top layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting model training...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "history = classifier.train(\n",
    "    train_gen,\n",
    "    val_gen,\n",
    "    epochs=30,  # Initial training epochs\n",
    "    fine_tune_epochs=5  # Fine-tuning epochs\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot training history\n",
    "classifier.plot_training_history('../models/training_history.png')\n",
    "print(\"Training history plots saved.\")"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Model Evaluation with Multiple Metrics\n",
    "\n",
    "Evaluate the model using comprehensive metrics:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-Score\n",
    "- Confusion Matrix\n",
    "- Per-class metrics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Evaluate on validation set\n",
    "print(\"Evaluating model on validation set...\")\n",
    "results = classifier.evaluate(val_gen)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"EVALUATION RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nOverall Accuracy: {results['accuracy']:.4f}\")\n",
    "print(f\"Weighted Precision: {results['precision']:.4f}\")\n",
    "print(f\"Weighted Recall: {results['recall']:.4f}\")\n",
    "print(f\"Weighted F1-Score: {results['f1_score']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 50)\n",
    "print(\"Per-Class Metrics:\")\n",
    "print(\"-\" * 50)\n",
    "for class_name in results['class_names']:\n",
    "    if class_name in results['classification_report']:\n",
    "        metrics = results['classification_report'][class_name]\n",
    "        print(f\"\\n{class_name.upper()}:\")\n",
    "        print(f\"  Precision: {metrics['precision']:.4f}\")\n",
    "        print(f\"  Recall: {metrics['recall']:.4f}\")\n",
    "        print(f\"  F1-Score: {metrics['f1-score']:.4f}\")\n",
    "        print(f\"  Support: {metrics['support']}\")"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot confusion matrix\n",
    "classifier.plot_confusion_matrix(\n",
    "    results['confusion_matrix'],\n",
    "    results['class_names'],\n",
    "    '../models/confusion_matrix.png'\n",
    ")\n",
    "print(\"Confusion matrix saved.\")\n",
    "\n",
    "# Display confusion matrix in notebook\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    results['confusion_matrix'],\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=results['class_names'],\n",
    "    yticklabels=results['class_names']\n",
    ")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Detailed classification report\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"DETAILED CLASSIFICATION REPORT\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(\n",
    "    val_gen.classes,\n",
    "    np.argmax(classifier.model.predict(val_gen), axis=1),\n",
    "    target_names=results['class_names']\n",
    "))"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Model Testing on Test Set\n",
    "\n",
    "Evaluate the model on the test set to get final performance metrics."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Prepare test data generator\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Test samples: {test_gen.samples}\")\n",
    "print(f\"Test classes: {list(test_gen.class_indices.keys())}\")"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Evaluate on test set\n",
    "print(\"Evaluating model on test set...\")\n",
    "test_results = classifier.evaluate(test_gen)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"TEST SET EVALUATION RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nTest Accuracy: {test_results['accuracy']:.4f}\")\n",
    "print(f\"Test Precision: {test_results['precision']:.4f}\")\n",
    "print(f\"Test Recall: {test_results['recall']:.4f}\")\n",
    "print(f\"Test F1-Score: {test_results['f1_score']:.4f}\")\n",
    "\n",
    "# Plot test confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    test_results['confusion_matrix'],\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Greens',\n",
    "    xticklabels=test_results['class_names'],\n",
    "    yticklabels=test_results['class_names']\n",
    ")\n",
    "plt.title('Test Set Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Model Prediction Functions\n",
    "\n",
    "Test the model with individual predictions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Import prediction module\n",
    "from prediction import BrainTumorPredictor\n",
    "\n",
    "# Load predictor\n",
    "predictor = BrainTumorPredictor('../models/brain_tumor_model.h5')\n",
    "\n",
    "print(\"Predictor loaded successfully!\")\n",
    "print(f\"Model classes: {predictor.class_names}\")"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Test prediction on a sample image\n",
    "sample_class = class_names[0]\n",
    "sample_path = os.path.join(test_dir, sample_class)\n",
    "sample_images = [f for f in os.listdir(sample_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "if sample_images:\n",
    "    test_image_path = os.path.join(sample_path, sample_images[0])\n",
    "    \n",
    "    # Make prediction\n",
    "    result = predictor.predict(test_image_path, return_probabilities=True)\n",
    "    \n",
    "    # Display image and prediction\n",
    "    img = cv2.imread(test_image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title(f'Test Image\\nTrue Class: {sample_class}')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Plot probabilities\n",
    "    classes = list(result['probabilities'].keys())\n",
    "    probs = list(result['probabilities'].values())\n",
    "    colors = ['green' if c == result['predicted_class'] else 'gray' for c in classes]\n",
    "    \n",
    "    axes[1].barh(classes, probs, color=colors)\n",
    "    axes[1].set_xlabel('Probability')\n",
    "    axes[1].set_title(f'Prediction Results\\nPredicted: {result[\"predicted_class\"]} ({result[\"confidence\"]*100:.2f}%)')\n",
    "    axes[1].set_xlim([0, 1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nPrediction Results:\")\n",
    "    print(f\"True Class: {sample_class}\")\n",
    "    print(f\"Predicted Class: {result['predicted_class']}\")\n",
    "    print(f\"Confidence: {result['confidence']*100:.2f}%\")\n",
    "    print(f\"\\nAll Probabilities:\")\n",
    "    for class_name, prob in result['probabilities'].items():\n",
    "        print(f\"  {class_name}: {prob*100:.2f}%\")"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Save the model\n",
    "classifier.save_model('../models/brain_tumor_model.h5')\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# Save class names\n",
    "import pickle\n",
    "with open('../models/class_names.pkl', 'wb') as f:\n",
    "    pickle.dump(class_names, f)\n",
    "print(\"Class names saved!\")"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated a complete ML pipeline for brain tumor classification:\n",
    "\n",
    "1. ✅ **Data Exploration**: Analyzed dataset structure and class distribution\n",
    "2. ✅ **Feature Extraction**: Extracted image features and saved to CSV\n",
    "3. ✅ **Model Creation**: Built transfer learning model with VGG16\n",
    "4. ✅ **Optimization**: Applied early stopping, learning rate reduction, data augmentation, dropout, and batch normalization\n",
    "5. ✅ **Training**: Trained model with fine-tuning\n",
    "6. ✅ **Evaluation**: Comprehensive evaluation with Accuracy, Precision, Recall, F1-Score, and Confusion Matrix\n",
    "7. ✅ **Testing**: Evaluated on test set\n",
    "8. ✅ **Prediction**: Tested prediction functionality\n",
    "\n",
    "The model is now ready for deployment!\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}